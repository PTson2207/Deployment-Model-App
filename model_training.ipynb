{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "mount_file_id": "12ZLq9TV1T7_9YaDC5GiqOHN4FtEVAQzz",
      "authorship_tag": "ABX9TyNCVLr4dmI7wzkezWhJQUhf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PTson2207/Deployment-Model-App/blob/main/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39c1oovB7crR"
      },
      "source": [
        "Training someone model, then deploy ...\n",
        "\n",
        "- Want: Save_model and then upload Google Storage\n",
        "- Data: From Kaggle-Food 101\n",
        "- Model(s): 10, 11, 12 classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogimD5Mv9PoP"
      },
      "source": [
        "Setup some Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z__jj4Zq7PmD"
      },
      "source": [
        "# thư viện\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers.experimental import preprocessing"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWUp2zRP_GfS"
      },
      "source": [
        "# Hàm unzip dowload_data file\n",
        "\n",
        "def unzip_data(file_name):\n",
        "    zip_ref = zipfile.ZipFile(file_name, 'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExiNrsIDAcJu"
      },
      "source": [
        "# Setup dataset input\n",
        "IMG_SIZE = (224, 224)\n",
        "\n",
        "def create_data_loader(train_dir, test_dir, img_size=IMG_SIZE):\n",
        "    train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
        "                                                                     label_mode=\"categorical\",\n",
        "                                                                     img_size=img_size)\n",
        "    \n",
        "    test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
        "                                                                    label_mode=\"categorical\",\n",
        "                                                                    img_size=img_size)\n",
        "    return train_data, test_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y_4f-X0e6SF"
      },
      "source": [
        "data_augument = keras.Sequential([\n",
        "                                  preprocessing.RandomFlip('horizontal'),\n",
        "                                  preprocessing.RandomRotation(0.2),\n",
        "                                  preprocessing.RandomHeight(0.2),\n",
        "                                  preprocessing.RandomWidth(0.2),\n",
        "                                  preprocessing.RandomZoom(0.2),\n",
        "                                  #preprocessing.Rescaling(1./255) # cho Resnet50V2, không cần thiết với EfficientNetB0\n",
        "], name=\"data_augument\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR12EEfSkd9y"
      },
      "source": [
        "# setup input_shape and base_model\n",
        "INPUT_SHAPE = (244, 244, 3)\n",
        "BASE_MODEL = tf.keras.applications.EfficientNetB0(include_top=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlpZhhzPlLwo"
      },
      "source": [
        "def create_model(input_shape=INPUT_SHAPE, base_model=BASE_MODEL, num_classes=10):\n",
        "    # Fine tune model\n",
        "    base_model.trainable = False\n",
        "    # tạo layers\n",
        "    inputs = layers.Input(shape=INPUT_SHAPE, name=\"input_layer\")\n",
        "    # thêm data_augument như một layer\n",
        "    x = data_augument(inputs)\n",
        "    # give model inputs (after augument) nhưng không train\n",
        "    x = base_model(x, training= False)\n",
        "    # Pool layer\n",
        "    x = layers.GlobalAveragePooling2D(name='pooling_layers')(x)\n",
        "    # put a dense layer as a out_put\n",
        "    outputs = layers.Dense(num_classes, activation='softmax', name='output_layers')(x)\n",
        "\n",
        "    # model từ input và output\n",
        "    model = keras.Model(inputs, outputs)\n",
        "\n",
        "    model.complie(loss=\"categorical_crossentropy\",\n",
        "                  optimizer=tf.keras.optimizers.Adam(),\n",
        "                  metrics=['accuracy'])\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gd_dX4NMpJE"
      },
      "source": [
        "# Hàm import ảnh và resize ảnh\n",
        "def load_and_prep_img(filename, img_shape=244, scale=False):\n",
        "    # đọc ảnh\n",
        "    img = tf.io.read_file(file_name)\n",
        "    # dịch ảnh sang tensor unit8\n",
        "    img = tf.image.decode_jpeg(img)\n",
        "    # thay đổi kích thước ảnh\n",
        "    img = tf.image.resize(img, [img_shape, img_shape])\n",
        "    # đổi giá trị ảnh về giữa đoạn 0 đến 1\n",
        "    if scale:\n",
        "        return img/255\n",
        "    else:\n",
        "        return img"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlZiPbfoPX5y"
      },
      "source": [
        "Download Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jmpjp_2iPbEw",
        "outputId": "cdc1f262-1a46-4b9c-97f3-8146805fe16c"
      },
      "source": [
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
        "\n",
        "unzip_data(\"10_food_classes_all_data.zip\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-19 06:49:24--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.101.128, 2607:f8b0:4023:c03::80, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 519183241 (495M) [application/zip]\n",
            "Saving to: ‘10_food_classes_all_data.zip’\n",
            "\n",
            "10_food_classes_all 100%[===================>] 495.13M   218MB/s    in 2.3s    \n",
            "\n",
            "2021-03-19 06:49:27 (218 MB/s) - ‘10_food_classes_all_data.zip’ saved [519183241/519183241]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1pm0C5rRbxf",
        "outputId": "d10efded-8569-4def-ba4a-b73c191f6b1b"
      },
      "source": [
        "# có bao nhiêu ảnh trong mỗi folder ?\n",
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_all_data\"):\n",
        "    print(f\"Có {len(dirnames)} thư mục con và có {len(filenames)} ảnh trong thư mục '{dirpath}'.\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Có 2 thư mục con và có 0 ảnh trong thư mục '10_food_classes_all_data'.\n",
            "Có 10 thư mục con và có 0 ảnh trong thư mục '10_food_classes_all_data/train'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/pizza'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/fried_rice'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/sushi'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/hamburger'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/steak'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/grilled_salmon'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/ice_cream'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/chicken_curry'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/chicken_wings'.\n",
            "Có 0 thư mục con và có 750 ảnh trong thư mục '10_food_classes_all_data/train/ramen'.\n",
            "Có 10 thư mục con và có 0 ảnh trong thư mục '10_food_classes_all_data/test'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/pizza'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/fried_rice'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/sushi'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/hamburger'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/steak'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/grilled_salmon'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/ice_cream'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/chicken_curry'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/chicken_wings'.\n",
            "Có 0 thư mục con và có 250 ảnh trong thư mục '10_food_classes_all_data/test/ramen'.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1rSM8DaW1o1"
      },
      "source": [
        "# hàm tạo nhằm mục đích load lại mỗi khi chạy mới mô hình\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "    log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "        log_dir = log_dir\n",
        "    )\n",
        "    print(f\"Lưu tệp nhật kí vào {log_dir}\")\n",
        "    return tensorboard_callback"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sU3aqLxYNva"
      },
      "source": [
        "    Vì ta có khả năng có thể chạy lại model nhiều lần, vì thế ta có thể theo dõi chúng theo một cách nào đó.\n",
        "    Hàm trên lưu lại nhật kí hiệu suất mô hình ở thư mục: [dir_name]/[experiment_name]/[current_timestamp]:\n",
        "    - dir_name:  thư mục lưu lại nhật kí tổng thể.\n",
        "    - experiment_name: thử nghiệm cụ thể.\n",
        "    - current_timestamp: thời gian thử nghiệm chi tiết."
      ]
    }
  ]
}